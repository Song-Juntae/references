# 모두의 연구소

## 모두팝

AI 스토리_[모두팝] AI+ ImageNet

이진원은 모두의 연구소에서 이미지넷에 대한 발표를 하며, 이미지넷의 시작과 딥러닝 시대에 미친 영향, 그리고 다양한 모델들의 발전 과정을 설명한다. 페이페이 리 교수가 시작한 이 프로젝트는 대규모 이미지 수집과 레이블링 작업을 통해 인공지능 분야에 중요한 데이터셋을 제공하였다. 알렉스넷, Vgg, 구글넷 등 여러 네트워크가 딥러닝 발전에 기여했으며, 오토ml의 등장과 함께 모델 생성 과정에서 사람의 역할이 변화하고 있다. 비전 트랜스포머와 같은 새로운 아키텍처가 제안되며, AI 반도체 개발에서 네트워크의 효율성 및 실행 속도가 중요한 연구 주제로 부상하였다.

* 이미지넷의 역사와 발전 과정
    * thumbnail_이미지넷의 역사와 발전 과정
    * 이진원이 모두의 연구소에서 이미지넷에 대해 발표하다.
    * 이미지넷이 어떻게 시작되었고, 어떤 모델들이 성능 경쟁을 했는지 설명하다.
    * 이미지넷 데이터셋의 크기와 참여 국가 수를 공유하다.

* 페이페이 리 교수와 이미지넷 프로젝트
    * thumbnail_페이페이 리 교수와 이미지넷 프로젝트
    * 페이페이 리 교수가 워드넷에 이미지를 추가하는 아이디어로부터 이미지넷 프로젝트를 시작하다.
    * 인터넷에서 대규모 이미지를 수집하고 아마존 메카니컬 터크를 활용해 레이블링 작업을 진행하다.
    * 초기에는 자금과 인식의 어려움에도 불구하고, 프로젝트의 중요성을 믿고 계속 진행하다.

* 이미지넷의 영향력과 한계
    * thumbnail_이미지넷의 영향력과 한계
    * 이미지넷이 딥러닝 시대에 중요한 역할을 하였으나, 현재는 일부 문제점도 가진다고 지적하다.
    * 레이블링 과정에서의 애매모호함과 클래스 선택의 제한으로 인한 오류 사례를 소개하다.
    * 정확한 분류보다는 넓은 범위의 데이터 수집에 초점을 맞춘 결과로 볼 수 있다고 분석하다.

* 이미지넷의 변화와 딥러닝 혁명
    * thumbnail_이미지넷의 변화와 딥러닝 혁명
    * 이미지넷 레이블의 문제점과 다양한 데이터셋 변형이 등장하였다.
    * 2012년 알렉스넷의 등장으로 딥러닝 혁명이 시작되었다.
    * Vgg, googlenet 등의 네트워크가 딥러닝 발전에 기여했다.

* 딥러닝 모델의 발전과 도전
    * thumbnail_딥러닝 모델의 발전과 도전
    * 인공지능이 사람의 얼굴을 구분하기 위해서는 많은 특징과 채널이 필요하다.
    * Vgg 모델은 메모리와 파라미터 사용량이 많아서 운영에 어려움이 있다.
    * 구글넷과 레지넷은 혁신적인 구조로 인식 성능을 크게 향상시켰으나, 계속되는 레이어 증가에 따른 문제를 해결해야 했다.

* 딥러닝 기술의 진화와 최적화 문제
    * thumbnail_딥러닝 기술의 진화와 최적화 문제
    * 레지넷은 레이어를 대폭 증가시켜 성능을 개선했으나, 이로 인한 최적화 문제를 해결해야 했다.
    * 스킵 커넥션과 같은 새로운 아이디어를 도입하여 깊은 네트워크의 학습 문제를 개선했다.
    * 연구자들은 네트워크 구조의 변형과 최적화 방법을 지속적으로 탐색하며 딥러닝 기술을 발전시켜 나갔다.

* 딥러닝에서의 어텐션 메커니즘과 채널 중요도
    * thumbnail_딥러닝에서의 어텐션 메커니즘과 채널 중요도
    * 가로세로 방향과 채널 방향의 코렐레이션 차이를 설명하며, 특정 채널의 중요도를 계산하는 방법을 소개한다.
    * 글로벌 에이버리지 풀링과 fluentquence 레이어를 활용하여 채널별 중요도를 조절하는 과정을 설명한다.
    * 입력에 따라 변하는 어텐션의 특성과 이를 가능하게 하는 기술적 방법을 설명한다.

* 오토ML의 진화와 랜덤 네트워크 디자인
    * thumbnail_오토ML의 진화와 랜덤 네트워크 디자인
    * 오토ml의 등장 배경과 neural architecture search 기술의 발전 과정을 소개한다.
    * 나스넷과 아메바넷 같은 오토ml 모델들의 구조와 성능에 대해 설명하며, 진화 알고리즘 기반 접근 방식을 비교한다.
    * 랜덤 리와이어드 네트워크가 가져온 충격적인 결과와 그 의미에 대해 탐구한다.

* 딥러닝에서 사람과 기계의 역할 변화
    * thumbnail_딥러닝에서 사람과 기계의 역할 변화
    * Automl 시대가 도래하면서 모델 생성 과정에서 사람의 역할이 변화하고 있다는 점을 강조한다.
    * Efficientnet 같은 모델들은 automl로 찾아진 구조를 사람이 수정하여 성능을 개선한 예시로 소개된다.
    * 딥러닝 및 automl 기술 발전으로 인한 사람과 기계 간 역할 변화와 그 의미에 대해 탐구한다.

* 모델 스케일링의 이해와 적용
    * thumbnail_모델 스케일링의 이해와 적용
    * 모델을 키우는 세 가지 방법으로 위스 스케일링, 뎁스 스케일링, 레졸루션 스케일링이 있으며 각각 채널 증가, 레이어 추가, 해상도 향상을 의미한다.
    * 컴파운드 스케일링은 이 세 가지 방법을 조합하여 모델의 성능을 효율적으로 향상시키는 전략이다.
    * 알파, 베타, 감마를 조정하여 최적의 네트워크 구조를 찾고, 이를 바탕으로 모델을 확장하는 과정에서 연산량과 성능 간의 균형을 맞춘다.

* 데이터와 모델 크기의 중요성
    * thumbnail_데이터와 모델 크기의 중요성
    * 큰 모델과 대량의 데이터를 사용한 사전 학습 및 파인튜닝 접근법이 자연어 처리뿐만 아니라 비전 분야에서도 유효함을 보여준다.
    * Bit와 같은 방법론은 엄청난 양의 데이터로 프리트레이닝 후 작은 데이터셋으로 파인튜닝하여 높은 성능 달성 가능성을 제시한다.
    * 모델과 데이터를 동시에 확장하는 것이 성능 향상에 있어 매우 중요하며, 이는 다양한 실험을 통해 입증되었다.

* 비전 트랜스포머와 그 이후의 발전
    * thumbnail_비전 트랜스포머와 그 이후의 발전
    * 비전 트랜스포머(vit)는 이미지를 패치로 나누고 이를 벡터로 변환하여 트랜스포머 인코더에 입력하는 방식으로 이미지 분류 문제에 접근한다.
    * Vit는 대규모 데이터셋에서 우수한 성능을 보였으나 작은 데이터셋에서는 한계가 있음이 드러난다.
    * Vit 이후 mlp mixer 등 다양한 아키텍처가 제안되며 비전 분야에서도 트랜스포머 기반 모델들의 발전이 지속되고 있다.

* 트랜스포머와 컨볼루션의 비교
    * thumbnail_트랜스포머와 컨볼루션의 비교
    * 트랜스포머는 공간상으로 다른 위치의 데이터를 연산하며, mlp를 통해 벡터 간 연산을 수행한다.
    * 컨볼루션은 로컬한 정보를 중심으로 처리하지만, 트랜스포머는 전체적인 관점에서 데이터를 처리한다.
    * 어텐션 메커니즘은 입력 데이터에 따라 가중치가 변화하며, 이는 컨볼루션과의 주요 차이점 중 하나다.

* 네트워크 구조의 진화와 성능 개선
    * thumbnail_네트워크 구조의 진화와 성능 개선
    * Cnn과 vit 간의 비교 연구에서는 레이어 간 시뮬러리티와 평균 거리 계산을 통해 차이점을 분석한다.
    * 하이브리드 모델인 convolutional transformer가 등장하여 두 기술의 장점을 결합시키려는 시도가 이루어진다.
    * 최신 연구에서는 메타 러닝과 모델 앙상블 기법을 활용하여 이미지 인식 분야에서 90% 이상의 정확도 달성을 목표로 한다.

* 하이퍼파라미터 평균화와 그리디 선택 전략
    * thumbnail_하이퍼파라미터 평균화와 그리디 선택 전략
    * 하이퍼파라미터 튜닝 후 최적의 모델을 선택하는 대신, 여러 모델의 가중치를 평균화하여 성능을 향상시키는 방법을 제안한다.
    * 성능이 좋은 모델만을 선택하는 그리디 방식과 달리, 평균화를 통해 더 나은 결과를 얻을 수 있다는 점을 강조한다.
    * 이러한 접근 방식은 최종적으로 90.94%의 성능 향상을 보여준다.

* 코카 모델과 멀티모달 학습의 진보
    * thumbnail_코카 모델과 멀티모달 학습의 진보
    * 코카 모델은 crossentropy loss를 사용하지 않고 이미지와 텍스트 멀티모달 학습에 사용되며, 프리트레이닝과 파인튜닝 전략을 적용한다.
    * 이 모델은 다양한 태스크에서 높은 성능을 보여주며, 특히 제로샷 학습에서도 86% 이상의 성능을 달성한다.
    * 코카는 기존 모델들과 비교하여 구조적으로 복잡하지 않음에도 불구하고 뛰어난 결과를 보여준다.

* AI 반도체와 네트워크 연구 동향
    * thumbnail_AI 반도체와 네트워크 연구 동향
    * Ai 반도체 개발에 있어서 네트워크의 효율성 및 실행 속도가 중요한 연구 주제로 부상하고 있다.
    * 현재 연구는 하드웨어 친화적인 네트워크 설계에 초점을 맞추고 있으며, 이는 특히 트랜스포머와 같은 모델에서 중요하다.
    * 연사는 ai 반도체 분야에서의 경험과 함께 현재 및 미래 연구 동향에 대해 공유한다.

